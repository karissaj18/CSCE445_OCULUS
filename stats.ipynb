{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0c8ca1ce-493b-4672-8e42-73dc5353d128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved filtered data for participant 101 to p_101_fixations\n",
      "Saved filtered data for participant 102 to p_102_fixations\n",
      "Saved filtered data for participant 104 to p_104_fixations\n",
      "Saved filtered data for participant 106 to p_106_fixations\n",
      "Saved filtered data for participant 109 to p_109_fixations\n",
      "Saved filtered data for participant 10 to p_10_fixations\n",
      "Saved filtered data for participant 110 to p_110_fixations\n",
      "Saved filtered data for participant 112 to p_112_fixations\n",
      "Saved filtered data for participant 113 to p_113_fixations\n",
      "Saved filtered data for participant 114 to p_114_fixations\n",
      "Saved filtered data for participant 115 to p_115_fixations\n",
      "Saved filtered data for participant 116 to p_116_fixations\n",
      "Saved filtered data for participant 118 to p_118_fixations\n",
      "Saved filtered data for participant 122 to p_122_fixations\n",
      "Saved filtered data for participant 123 to p_123_fixations\n",
      "Saved filtered data for participant 126 to p_126_fixations\n",
      "Saved filtered data for participant 128 to p_128_fixations\n",
      "Saved filtered data for participant 129 to p_129_fixations\n",
      "Saved filtered data for participant 12 to p_12_fixations\n",
      "Saved filtered data for participant 132 to p_132_fixations\n",
      "Saved filtered data for participant 133 to p_133_fixations\n",
      "Saved filtered data for participant 135 to p_135_fixations\n",
      "Saved filtered data for participant 137 to p_137_fixations\n",
      "Saved filtered data for participant 138 to p_138_fixations\n",
      "Saved filtered data for participant 13 to p_13_fixations\n",
      "Saved filtered data for participant 140 to p_140_fixations\n",
      "Saved filtered data for participant 141 to p_141_fixations\n",
      "Saved filtered data for participant 142 to p_142_fixations\n",
      "Saved filtered data for participant 143 to p_143_fixations\n",
      "Saved filtered data for participant 145 to p_145_fixations\n",
      "Saved filtered data for participant 147 to p_147_fixations\n",
      "Saved filtered data for participant 148 to p_148_fixations\n",
      "Saved filtered data for participant 149 to p_149_fixations\n",
      "Saved filtered data for participant 14 to p_14_fixations\n",
      "Saved filtered data for participant 151 to p_151_fixations\n",
      "Saved filtered data for participant 152 to p_152_fixations\n",
      "Saved filtered data for participant 154 to p_154_fixations\n",
      "Saved filtered data for participant 155 to p_155_fixations\n",
      "Saved filtered data for participant 156 to p_156_fixations\n",
      "Saved filtered data for participant 157 to p_157_fixations\n",
      "Saved filtered data for participant 158 to p_158_fixations\n",
      "Saved filtered data for participant 159 to p_159_fixations\n",
      "Saved filtered data for participant 160 to p_160_fixations\n",
      "Saved filtered data for participant 161 to p_161_fixations\n",
      "Saved filtered data for participant 162 to p_162_fixations\n",
      "Saved filtered data for participant 165 to p_165_fixations\n",
      "Saved filtered data for participant 168 to p_168_fixations\n",
      "Saved filtered data for participant 16 to p_16_fixations\n",
      "Saved filtered data for participant 170 to p_170_fixations\n",
      "Saved filtered data for participant 171 to p_171_fixations\n",
      "Saved filtered data for participant 172 to p_172_fixations\n",
      "Saved filtered data for participant 175 to p_175_fixations\n",
      "Saved filtered data for participant 176 to p_176_fixations\n",
      "Saved filtered data for participant 178 to p_178_fixations\n",
      "Saved filtered data for participant 181 to p_181_fixations\n",
      "Saved filtered data for participant 183 to p_183_fixations\n",
      "Saved filtered data for participant 184 to p_184_fixations\n",
      "Saved filtered data for participant 185 to p_185_fixations\n",
      "Saved filtered data for participant 186 to p_186_fixations\n",
      "Saved filtered data for participant 187 to p_187_fixations\n",
      "Saved filtered data for participant 188 to p_188_fixations\n",
      "Saved filtered data for participant 189 to p_189_fixations\n",
      "Saved filtered data for participant 190 to p_190_fixations\n",
      "Saved filtered data for participant 191 to p_191_fixations\n",
      "Saved filtered data for participant 193 to p_193_fixations\n",
      "Saved filtered data for participant 195 to p_195_fixations\n",
      "Saved filtered data for participant 196 to p_196_fixations\n",
      "Saved filtered data for participant 198 to p_198_fixations\n",
      "Saved filtered data for participant 1 to p_1_fixations\n",
      "Saved filtered data for participant 201 to p_201_fixations\n",
      "Saved filtered data for participant 205 to p_205_fixations\n",
      "Saved filtered data for participant 207 to p_207_fixations\n",
      "Saved filtered data for participant 20 to p_20_fixations\n",
      "Saved filtered data for participant 210 to p_210_fixations\n",
      "Saved filtered data for participant 212 to p_212_fixations\n",
      "Saved filtered data for participant 213 to p_213_fixations\n",
      "Saved filtered data for participant 214 to p_214_fixations\n",
      "Saved filtered data for participant 215 to p_215_fixations\n",
      "Saved filtered data for participant 216 to p_216_fixations\n",
      "Saved filtered data for participant 21 to p_21_fixations\n",
      "Saved filtered data for participant 22 to p_22_fixations\n",
      "Saved filtered data for participant 23 to p_23_fixations\n",
      "Saved filtered data for participant 24 to p_24_fixations\n",
      "Saved filtered data for participant 25 to p_25_fixations\n",
      "Saved filtered data for participant 26 to p_26_fixations\n",
      "Saved filtered data for participant 28 to p_28_fixations\n",
      "Saved filtered data for participant 29 to p_29_fixations\n",
      "Saved filtered data for participant 2 to p_2_fixations\n",
      "Saved filtered data for participant 31 to p_31_fixations\n",
      "Saved filtered data for participant 32 to p_32_fixations\n",
      "Saved filtered data for participant 33 to p_33_fixations\n",
      "Saved filtered data for participant 34 to p_34_fixations\n",
      "Saved filtered data for participant 35 to p_35_fixations\n",
      "Saved filtered data for participant 38 to p_38_fixations\n",
      "Saved filtered data for participant 39 to p_39_fixations\n",
      "Saved filtered data for participant 41 to p_41_fixations\n",
      "Saved filtered data for participant 42 to p_42_fixations\n",
      "Saved filtered data for participant 44 to p_44_fixations\n",
      "Saved filtered data for participant 45 to p_45_fixations\n",
      "Saved filtered data for participant 46 to p_46_fixations\n",
      "Saved filtered data for participant 47 to p_47_fixations\n",
      "Saved filtered data for participant 49 to p_49_fixations\n",
      "Saved filtered data for participant 4 to p_4_fixations\n",
      "Saved filtered data for participant 50 to p_50_fixations\n",
      "Saved filtered data for participant 51 to p_51_fixations\n",
      "Saved filtered data for participant 52 to p_52_fixations\n",
      "Saved filtered data for participant 53 to p_53_fixations\n",
      "Saved filtered data for participant 55 to p_55_fixations\n",
      "Saved filtered data for participant 56 to p_56_fixations\n",
      "Saved filtered data for participant 59 to p_59_fixations\n",
      "Saved filtered data for participant 5 to p_5_fixations\n",
      "Saved filtered data for participant 60 to p_60_fixations\n",
      "Saved filtered data for participant 61 to p_61_fixations\n",
      "Saved filtered data for participant 63 to p_63_fixations\n",
      "Saved filtered data for participant 66 to p_66_fixations\n",
      "Saved filtered data for participant 67 to p_67_fixations\n",
      "Saved filtered data for participant 69 to p_69_fixations\n",
      "Saved filtered data for participant 6 to p_6_fixations\n",
      "Saved filtered data for participant 70 to p_70_fixations\n",
      "Saved filtered data for participant 73 to p_73_fixations\n",
      "Saved filtered data for participant 74 to p_74_fixations\n",
      "Saved filtered data for participant 75 to p_75_fixations\n",
      "Saved filtered data for participant 77 to p_77_fixations\n",
      "Saved filtered data for participant 78 to p_78_fixations\n",
      "Saved filtered data for participant 79 to p_79_fixations\n",
      "Saved filtered data for participant 7 to p_7_fixations\n",
      "Saved filtered data for participant 80 to p_80_fixations\n",
      "Saved filtered data for participant 82 to p_82_fixations\n",
      "Saved filtered data for participant 84 to p_84_fixations\n",
      "Saved filtered data for participant 85 to p_85_fixations\n",
      "Saved filtered data for participant 86 to p_86_fixations\n",
      "Saved filtered data for participant 87 to p_87_fixations\n",
      "Saved filtered data for participant 88 to p_88_fixations\n",
      "Saved filtered data for participant 89 to p_89_fixations\n",
      "Saved filtered data for participant 8 to p_8_fixations\n",
      "Saved filtered data for participant 90 to p_90_fixations\n",
      "Saved filtered data for participant 91 to p_91_fixations\n",
      "Saved filtered data for participant 94 to p_94_fixations\n",
      "Saved filtered data for participant 95 to p_95_fixations\n",
      "Saved filtered data for participant 96 to p_96_fixations\n",
      "Saved filtered data for participant 97 to p_97_fixations\n",
      "Saved filtered data for participant 99 to p_99_fixations\n",
      "Saved filtered data for participant 9 to p_9_fixations\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the array of participant values to filter by\n",
    "participant_values = [3, 30, 36, 38, 90, 93, 119, 146, 167, 181, 216]\n",
    "\n",
    "folder_path = 'native'  # Replace with the actual folder path\n",
    "new_folder_path = 'programming_none'\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # Check if the file is a CSV file\n",
    "    if file_name.endswith('.csv'):\n",
    "        # Build the full file path\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Check if 'participants' column exists\n",
    "        if 'participant' in df.columns:\n",
    "            # Filter the rows where 'participants' is in the participant_values array\n",
    "            filtered_df = df[df['participant'].isin(participant_values)]\n",
    "            \n",
    "            # If there are any rows after filtering, save them to a new file\n",
    "            if not filtered_df.empty:\n",
    "                for participant in filtered_df['participant'].unique():\n",
    "                    # Create a new file name based on the participant value\n",
    "                    new_file_name = f\"{'p'}_{participant}_{'fixations'}\"\n",
    "                    new_file_path = os.path.join(new_folder_path, new_file_name)\n",
    "                    \n",
    "                    # Save the filtered data to a new CSV file\n",
    "                    filtered_df[filtered_df['participant'] == participant].to_csv(new_file_path, index=False)\n",
    "                    print(f\"Saved filtered data for participant {participant} to {new_file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2b72dcf2-cecd-47e0-a720-2cf128bcd235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File p_100_fixations has been processed, saved as ltr\\p_100_fixations.csv, and deleted.\n",
      "File p_101_fixations has been processed, saved as ltr\\p_101_fixations.csv, and deleted.\n",
      "File p_102_fixations has been processed, saved as ltr\\p_102_fixations.csv, and deleted.\n",
      "File p_103_fixations has been processed, saved as ltr\\p_103_fixations.csv, and deleted.\n",
      "File p_104_fixations has been processed, saved as ltr\\p_104_fixations.csv, and deleted.\n",
      "File p_105_fixations has been processed, saved as ltr\\p_105_fixations.csv, and deleted.\n",
      "File p_106_fixations has been processed, saved as ltr\\p_106_fixations.csv, and deleted.\n",
      "File p_107_fixations has been processed, saved as ltr\\p_107_fixations.csv, and deleted.\n",
      "File p_108_fixations has been processed, saved as ltr\\p_108_fixations.csv, and deleted.\n",
      "File p_109_fixations has been processed, saved as ltr\\p_109_fixations.csv, and deleted.\n",
      "File p_10_fixations has been processed, saved as ltr\\p_10_fixations.csv, and deleted.\n",
      "File p_110_fixations has been processed, saved as ltr\\p_110_fixations.csv, and deleted.\n",
      "File p_111_fixations has been processed, saved as ltr\\p_111_fixations.csv, and deleted.\n",
      "File p_112_fixations has been processed, saved as ltr\\p_112_fixations.csv, and deleted.\n",
      "File p_113_fixations has been processed, saved as ltr\\p_113_fixations.csv, and deleted.\n",
      "File p_114_fixations has been processed, saved as ltr\\p_114_fixations.csv, and deleted.\n",
      "File p_115_fixations has been processed, saved as ltr\\p_115_fixations.csv, and deleted.\n",
      "File p_116_fixations has been processed, saved as ltr\\p_116_fixations.csv, and deleted.\n",
      "File p_117_fixations has been processed, saved as ltr\\p_117_fixations.csv, and deleted.\n",
      "File p_118_fixations has been processed, saved as ltr\\p_118_fixations.csv, and deleted.\n",
      "File p_119_fixations has been processed, saved as ltr\\p_119_fixations.csv, and deleted.\n",
      "File p_11_fixations has been processed, saved as ltr\\p_11_fixations.csv, and deleted.\n",
      "File p_120_fixations has been processed, saved as ltr\\p_120_fixations.csv, and deleted.\n",
      "File p_121_fixations has been processed, saved as ltr\\p_121_fixations.csv, and deleted.\n",
      "File p_122_fixations has been processed, saved as ltr\\p_122_fixations.csv, and deleted.\n",
      "File p_123_fixations has been processed, saved as ltr\\p_123_fixations.csv, and deleted.\n",
      "File p_124_fixations has been processed, saved as ltr\\p_124_fixations.csv, and deleted.\n",
      "File p_125_fixations has been processed, saved as ltr\\p_125_fixations.csv, and deleted.\n",
      "File p_126_fixations has been processed, saved as ltr\\p_126_fixations.csv, and deleted.\n",
      "File p_127_fixations has been processed, saved as ltr\\p_127_fixations.csv, and deleted.\n",
      "File p_128_fixations has been processed, saved as ltr\\p_128_fixations.csv, and deleted.\n",
      "File p_129_fixations has been processed, saved as ltr\\p_129_fixations.csv, and deleted.\n",
      "File p_12_fixations has been processed, saved as ltr\\p_12_fixations.csv, and deleted.\n",
      "File p_130_fixations has been processed, saved as ltr\\p_130_fixations.csv, and deleted.\n",
      "File p_131_fixations has been processed, saved as ltr\\p_131_fixations.csv, and deleted.\n",
      "File p_132_fixations has been processed, saved as ltr\\p_132_fixations.csv, and deleted.\n",
      "File p_133_fixations has been processed, saved as ltr\\p_133_fixations.csv, and deleted.\n",
      "File p_135_fixations has been processed, saved as ltr\\p_135_fixations.csv, and deleted.\n",
      "File p_136_fixations has been processed, saved as ltr\\p_136_fixations.csv, and deleted.\n",
      "File p_137_fixations has been processed, saved as ltr\\p_137_fixations.csv, and deleted.\n",
      "File p_138_fixations has been processed, saved as ltr\\p_138_fixations.csv, and deleted.\n",
      "File p_139_fixations has been processed, saved as ltr\\p_139_fixations.csv, and deleted.\n",
      "File p_13_fixations has been processed, saved as ltr\\p_13_fixations.csv, and deleted.\n",
      "File p_140_fixations has been processed, saved as ltr\\p_140_fixations.csv, and deleted.\n",
      "File p_141_fixations has been processed, saved as ltr\\p_141_fixations.csv, and deleted.\n",
      "File p_142_fixations has been processed, saved as ltr\\p_142_fixations.csv, and deleted.\n",
      "File p_143_fixations has been processed, saved as ltr\\p_143_fixations.csv, and deleted.\n",
      "File p_144_fixations has been processed, saved as ltr\\p_144_fixations.csv, and deleted.\n",
      "File p_145_fixations has been processed, saved as ltr\\p_145_fixations.csv, and deleted.\n",
      "File p_146_fixations has been processed, saved as ltr\\p_146_fixations.csv, and deleted.\n",
      "File p_147_fixations has been processed, saved as ltr\\p_147_fixations.csv, and deleted.\n",
      "File p_148_fixations has been processed, saved as ltr\\p_148_fixations.csv, and deleted.\n",
      "File p_149_fixations has been processed, saved as ltr\\p_149_fixations.csv, and deleted.\n",
      "File p_14_fixations has been processed, saved as ltr\\p_14_fixations.csv, and deleted.\n",
      "File p_150_fixations has been processed, saved as ltr\\p_150_fixations.csv, and deleted.\n",
      "File p_151_fixations has been processed, saved as ltr\\p_151_fixations.csv, and deleted.\n",
      "File p_152_fixations has been processed, saved as ltr\\p_152_fixations.csv, and deleted.\n",
      "File p_154_fixations has been processed, saved as ltr\\p_154_fixations.csv, and deleted.\n",
      "File p_155_fixations has been processed, saved as ltr\\p_155_fixations.csv, and deleted.\n",
      "File p_156_fixations has been processed, saved as ltr\\p_156_fixations.csv, and deleted.\n",
      "File p_157_fixations has been processed, saved as ltr\\p_157_fixations.csv, and deleted.\n",
      "File p_158_fixations has been processed, saved as ltr\\p_158_fixations.csv, and deleted.\n",
      "File p_159_fixations has been processed, saved as ltr\\p_159_fixations.csv, and deleted.\n",
      "File p_15_fixations has been processed, saved as ltr\\p_15_fixations.csv, and deleted.\n",
      "File p_160_fixations has been processed, saved as ltr\\p_160_fixations.csv, and deleted.\n",
      "File p_161_fixations has been processed, saved as ltr\\p_161_fixations.csv, and deleted.\n",
      "File p_162_fixations has been processed, saved as ltr\\p_162_fixations.csv, and deleted.\n",
      "File p_163_fixations has been processed, saved as ltr\\p_163_fixations.csv, and deleted.\n",
      "File p_164_fixations has been processed, saved as ltr\\p_164_fixations.csv, and deleted.\n",
      "File p_165_fixations has been processed, saved as ltr\\p_165_fixations.csv, and deleted.\n",
      "File p_166_fixations has been processed, saved as ltr\\p_166_fixations.csv, and deleted.\n",
      "File p_168_fixations has been processed, saved as ltr\\p_168_fixations.csv, and deleted.\n",
      "File p_169_fixations has been processed, saved as ltr\\p_169_fixations.csv, and deleted.\n",
      "File p_16_fixations has been processed, saved as ltr\\p_16_fixations.csv, and deleted.\n",
      "File p_170_fixations has been processed, saved as ltr\\p_170_fixations.csv, and deleted.\n",
      "File p_171_fixations has been processed, saved as ltr\\p_171_fixations.csv, and deleted.\n",
      "File p_172_fixations has been processed, saved as ltr\\p_172_fixations.csv, and deleted.\n",
      "File p_174_fixations has been processed, saved as ltr\\p_174_fixations.csv, and deleted.\n",
      "File p_175_fixations has been processed, saved as ltr\\p_175_fixations.csv, and deleted.\n",
      "File p_176_fixations has been processed, saved as ltr\\p_176_fixations.csv, and deleted.\n",
      "File p_178_fixations has been processed, saved as ltr\\p_178_fixations.csv, and deleted.\n",
      "File p_17_fixations has been processed, saved as ltr\\p_17_fixations.csv, and deleted.\n",
      "File p_180_fixations has been processed, saved as ltr\\p_180_fixations.csv, and deleted.\n",
      "File p_181_fixations has been processed, saved as ltr\\p_181_fixations.csv, and deleted.\n",
      "File p_182_fixations has been processed, saved as ltr\\p_182_fixations.csv, and deleted.\n",
      "File p_183_fixations has been processed, saved as ltr\\p_183_fixations.csv, and deleted.\n",
      "File p_184_fixations has been processed, saved as ltr\\p_184_fixations.csv, and deleted.\n",
      "File p_185_fixations has been processed, saved as ltr\\p_185_fixations.csv, and deleted.\n",
      "File p_186_fixations has been processed, saved as ltr\\p_186_fixations.csv, and deleted.\n",
      "File p_187_fixations has been processed, saved as ltr\\p_187_fixations.csv, and deleted.\n",
      "File p_188_fixations has been processed, saved as ltr\\p_188_fixations.csv, and deleted.\n",
      "File p_189_fixations has been processed, saved as ltr\\p_189_fixations.csv, and deleted.\n",
      "File p_18_fixations has been processed, saved as ltr\\p_18_fixations.csv, and deleted.\n",
      "File p_190_fixations has been processed, saved as ltr\\p_190_fixations.csv, and deleted.\n",
      "File p_191_fixations has been processed, saved as ltr\\p_191_fixations.csv, and deleted.\n",
      "File p_192_fixations has been processed, saved as ltr\\p_192_fixations.csv, and deleted.\n",
      "File p_193_fixations has been processed, saved as ltr\\p_193_fixations.csv, and deleted.\n",
      "File p_194_fixations has been processed, saved as ltr\\p_194_fixations.csv, and deleted.\n",
      "File p_195_fixations has been processed, saved as ltr\\p_195_fixations.csv, and deleted.\n",
      "File p_196_fixations has been processed, saved as ltr\\p_196_fixations.csv, and deleted.\n",
      "File p_197_fixations has been processed, saved as ltr\\p_197_fixations.csv, and deleted.\n",
      "File p_198_fixations has been processed, saved as ltr\\p_198_fixations.csv, and deleted.\n",
      "File p_199_fixations has been processed, saved as ltr\\p_199_fixations.csv, and deleted.\n",
      "File p_19_fixations has been processed, saved as ltr\\p_19_fixations.csv, and deleted.\n",
      "File p_1_fixations has been processed, saved as ltr\\p_1_fixations.csv, and deleted.\n",
      "File p_200_fixations has been processed, saved as ltr\\p_200_fixations.csv, and deleted.\n",
      "File p_201_fixations has been processed, saved as ltr\\p_201_fixations.csv, and deleted.\n",
      "File p_202_fixations has been processed, saved as ltr\\p_202_fixations.csv, and deleted.\n",
      "File p_203_fixations has been processed, saved as ltr\\p_203_fixations.csv, and deleted.\n",
      "File p_204_fixations has been processed, saved as ltr\\p_204_fixations.csv, and deleted.\n",
      "File p_205_fixations has been processed, saved as ltr\\p_205_fixations.csv, and deleted.\n",
      "File p_207_fixations has been processed, saved as ltr\\p_207_fixations.csv, and deleted.\n",
      "File p_209_fixations has been processed, saved as ltr\\p_209_fixations.csv, and deleted.\n",
      "File p_20_fixations has been processed, saved as ltr\\p_20_fixations.csv, and deleted.\n",
      "File p_210_fixations has been processed, saved as ltr\\p_210_fixations.csv, and deleted.\n",
      "File p_211_fixations has been processed, saved as ltr\\p_211_fixations.csv, and deleted.\n",
      "File p_212_fixations has been processed, saved as ltr\\p_212_fixations.csv, and deleted.\n",
      "File p_213_fixations has been processed, saved as ltr\\p_213_fixations.csv, and deleted.\n",
      "File p_214_fixations has been processed, saved as ltr\\p_214_fixations.csv, and deleted.\n",
      "File p_215_fixations has been processed, saved as ltr\\p_215_fixations.csv, and deleted.\n",
      "File p_216_fixations has been processed, saved as ltr\\p_216_fixations.csv, and deleted.\n",
      "File p_21_fixations has been processed, saved as ltr\\p_21_fixations.csv, and deleted.\n",
      "File p_22_fixations has been processed, saved as ltr\\p_22_fixations.csv, and deleted.\n",
      "File p_23_fixations has been processed, saved as ltr\\p_23_fixations.csv, and deleted.\n",
      "File p_24_fixations has been processed, saved as ltr\\p_24_fixations.csv, and deleted.\n",
      "File p_25_fixations has been processed, saved as ltr\\p_25_fixations.csv, and deleted.\n",
      "File p_26_fixations has been processed, saved as ltr\\p_26_fixations.csv, and deleted.\n",
      "File p_27_fixations has been processed, saved as ltr\\p_27_fixations.csv, and deleted.\n",
      "File p_28_fixations has been processed, saved as ltr\\p_28_fixations.csv, and deleted.\n",
      "File p_29_fixations has been processed, saved as ltr\\p_29_fixations.csv, and deleted.\n",
      "File p_2_fixations has been processed, saved as ltr\\p_2_fixations.csv, and deleted.\n",
      "File p_31_fixations has been processed, saved as ltr\\p_31_fixations.csv, and deleted.\n",
      "File p_32_fixations has been processed, saved as ltr\\p_32_fixations.csv, and deleted.\n",
      "File p_33_fixations has been processed, saved as ltr\\p_33_fixations.csv, and deleted.\n",
      "File p_34_fixations has been processed, saved as ltr\\p_34_fixations.csv, and deleted.\n",
      "File p_35_fixations has been processed, saved as ltr\\p_35_fixations.csv, and deleted.\n",
      "File p_36_fixations has been processed, saved as ltr\\p_36_fixations.csv, and deleted.\n",
      "File p_37_fixations has been processed, saved as ltr\\p_37_fixations.csv, and deleted.\n",
      "File p_38_fixations has been processed, saved as ltr\\p_38_fixations.csv, and deleted.\n",
      "File p_39_fixations has been processed, saved as ltr\\p_39_fixations.csv, and deleted.\n",
      "File p_40_fixations has been processed, saved as ltr\\p_40_fixations.csv, and deleted.\n",
      "File p_41_fixations has been processed, saved as ltr\\p_41_fixations.csv, and deleted.\n",
      "File p_42_fixations has been processed, saved as ltr\\p_42_fixations.csv, and deleted.\n",
      "File p_44_fixations has been processed, saved as ltr\\p_44_fixations.csv, and deleted.\n",
      "File p_45_fixations has been processed, saved as ltr\\p_45_fixations.csv, and deleted.\n",
      "File p_46_fixations has been processed, saved as ltr\\p_46_fixations.csv, and deleted.\n",
      "File p_47_fixations has been processed, saved as ltr\\p_47_fixations.csv, and deleted.\n",
      "File p_48_fixations has been processed, saved as ltr\\p_48_fixations.csv, and deleted.\n",
      "File p_49_fixations has been processed, saved as ltr\\p_49_fixations.csv, and deleted.\n",
      "File p_4_fixations has been processed, saved as ltr\\p_4_fixations.csv, and deleted.\n",
      "File p_50_fixations has been processed, saved as ltr\\p_50_fixations.csv, and deleted.\n",
      "File p_51_fixations has been processed, saved as ltr\\p_51_fixations.csv, and deleted.\n",
      "File p_52_fixations has been processed, saved as ltr\\p_52_fixations.csv, and deleted.\n",
      "File p_53_fixations has been processed, saved as ltr\\p_53_fixations.csv, and deleted.\n",
      "File p_54_fixations has been processed, saved as ltr\\p_54_fixations.csv, and deleted.\n",
      "File p_55_fixations has been processed, saved as ltr\\p_55_fixations.csv, and deleted.\n",
      "File p_56_fixations has been processed, saved as ltr\\p_56_fixations.csv, and deleted.\n",
      "File p_57_fixations has been processed, saved as ltr\\p_57_fixations.csv, and deleted.\n",
      "File p_58_fixations has been processed, saved as ltr\\p_58_fixations.csv, and deleted.\n",
      "File p_59_fixations has been processed, saved as ltr\\p_59_fixations.csv, and deleted.\n",
      "File p_5_fixations has been processed, saved as ltr\\p_5_fixations.csv, and deleted.\n",
      "File p_60_fixations has been processed, saved as ltr\\p_60_fixations.csv, and deleted.\n",
      "File p_61_fixations has been processed, saved as ltr\\p_61_fixations.csv, and deleted.\n",
      "File p_62_fixations has been processed, saved as ltr\\p_62_fixations.csv, and deleted.\n",
      "File p_63_fixations has been processed, saved as ltr\\p_63_fixations.csv, and deleted.\n",
      "File p_64_fixations has been processed, saved as ltr\\p_64_fixations.csv, and deleted.\n",
      "File p_65_fixations has been processed, saved as ltr\\p_65_fixations.csv, and deleted.\n",
      "File p_66_fixations has been processed, saved as ltr\\p_66_fixations.csv, and deleted.\n",
      "File p_67_fixations has been processed, saved as ltr\\p_67_fixations.csv, and deleted.\n",
      "File p_69_fixations has been processed, saved as ltr\\p_69_fixations.csv, and deleted.\n",
      "File p_6_fixations has been processed, saved as ltr\\p_6_fixations.csv, and deleted.\n",
      "File p_70_fixations has been processed, saved as ltr\\p_70_fixations.csv, and deleted.\n",
      "File p_71_fixations has been processed, saved as ltr\\p_71_fixations.csv, and deleted.\n",
      "File p_72_fixations has been processed, saved as ltr\\p_72_fixations.csv, and deleted.\n",
      "File p_73_fixations has been processed, saved as ltr\\p_73_fixations.csv, and deleted.\n",
      "File p_74_fixations has been processed, saved as ltr\\p_74_fixations.csv, and deleted.\n",
      "File p_75_fixations has been processed, saved as ltr\\p_75_fixations.csv, and deleted.\n",
      "File p_76_fixations has been processed, saved as ltr\\p_76_fixations.csv, and deleted.\n",
      "File p_77_fixations has been processed, saved as ltr\\p_77_fixations.csv, and deleted.\n",
      "File p_78_fixations has been processed, saved as ltr\\p_78_fixations.csv, and deleted.\n",
      "File p_79_fixations has been processed, saved as ltr\\p_79_fixations.csv, and deleted.\n",
      "File p_7_fixations has been processed, saved as ltr\\p_7_fixations.csv, and deleted.\n",
      "File p_80_fixations has been processed, saved as ltr\\p_80_fixations.csv, and deleted.\n",
      "File p_81_fixations has been processed, saved as ltr\\p_81_fixations.csv, and deleted.\n",
      "File p_82_fixations has been processed, saved as ltr\\p_82_fixations.csv, and deleted.\n",
      "File p_83_fixations has been processed, saved as ltr\\p_83_fixations.csv, and deleted.\n",
      "File p_84_fixations has been processed, saved as ltr\\p_84_fixations.csv, and deleted.\n",
      "File p_85_fixations has been processed, saved as ltr\\p_85_fixations.csv, and deleted.\n",
      "File p_86_fixations has been processed, saved as ltr\\p_86_fixations.csv, and deleted.\n",
      "File p_87_fixations has been processed, saved as ltr\\p_87_fixations.csv, and deleted.\n",
      "File p_88_fixations has been processed, saved as ltr\\p_88_fixations.csv, and deleted.\n",
      "File p_89_fixations has been processed, saved as ltr\\p_89_fixations.csv, and deleted.\n",
      "File p_8_fixations has been processed, saved as ltr\\p_8_fixations.csv, and deleted.\n",
      "File p_90_fixations has been processed, saved as ltr\\p_90_fixations.csv, and deleted.\n",
      "File p_91_fixations has been processed, saved as ltr\\p_91_fixations.csv, and deleted.\n",
      "File p_92_fixations has been processed, saved as ltr\\p_92_fixations.csv, and deleted.\n",
      "File p_93_fixations has been processed, saved as ltr\\p_93_fixations.csv, and deleted.\n",
      "File p_94_fixations has been processed, saved as ltr\\p_94_fixations.csv, and deleted.\n",
      "File p_95_fixations has been processed, saved as ltr\\p_95_fixations.csv, and deleted.\n",
      "File p_96_fixations has been processed, saved as ltr\\p_96_fixations.csv, and deleted.\n",
      "File p_97_fixations has been processed, saved as ltr\\p_97_fixations.csv, and deleted.\n",
      "File p_99_fixations has been processed, saved as ltr\\p_99_fixations.csv, and deleted.\n",
      "File p_9_fixations has been processed, saved as ltr\\p_9_fixations.csv, and deleted.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory containing the files\n",
    "folder_path = 'programming_none'  # Replace with the actual folder path\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # Build the full file path\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    try:\n",
    "        # Read the raw content of the file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        # Process the content and convert it into CSV format\n",
    "        # For example, assuming content is separated by newlines and commas\n",
    "        # You might need custom logic based on your actual content\n",
    "\n",
    "        # Split content by lines\n",
    "        lines = content.splitlines()\n",
    "\n",
    "        # Create a list to store rows for the CSV file\n",
    "        rows = []\n",
    "        for line in lines:\n",
    "            # Split each line by commas (or other delimiters based on your data)\n",
    "            rows.append(line.split(','))  # Adjust the delimiter if needed\n",
    "        \n",
    "        # Create a DataFrame from the rows\n",
    "        df = pd.DataFrame(rows)\n",
    "        \n",
    "        # Define new CSV file path with the same name but with '_new' appended\n",
    "        new_file_path = os.path.join(folder_path, f\"{os.path.splitext(file_name)[0]}.csv\")\n",
    "        \n",
    "        # Write the DataFrame to a new CSV file\n",
    "        df.to_csv(new_file_path, index=False, header=False)  # Set header=False if you don't want to write column headers\n",
    "        \n",
    "        # After successfully writing the new CSV file, delete the old file\n",
    "        os.remove(file_path)\n",
    "        \n",
    "        print(f\"File {file_name} has been processed, saved as {new_file_path}, and deleted.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "76bcbdcf-1eb9-4c86-975b-0149e9484d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CSV files have been combined into 'combined_output.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the directory containing the CSV files\n",
    "folder_path = 'programming_none'  # Replace with the actual folder path\n",
    "\n",
    "# Create an empty list to store dataframes\n",
    "all_data = []\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # Check if the file is a CSV file\n",
    "    if file_name.endswith('.csv'):\n",
    "        # Build the full file path\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        all_data.append(df)\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Save the combined dataframe to a new CSV file\n",
    "combined_df.to_csv('programming_none_aggregate.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "789b57da-e457-4dcc-9cac-dff20b5ff710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertical next text count for each participant from all files has been saved to 'combined_output.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of input file names\n",
    "input_files = ['programming_none_aggregate.csv', 'programming_low_aggregate.csv', 'programming_medium_aggregate.csv', 'programming_high_aggregate.csv']\n",
    "\n",
    "# List to store the results from all files\n",
    "all_results = []\n",
    "\n",
    "# Loop over each input file\n",
    "for file in input_files:\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Iterate through each participant in the current file\n",
    "    for participant in df['participant'].unique():\n",
    "        # Filter the DataFrame for the current participant\n",
    "        participant_data = df[df['participant'] == participant]\n",
    "        \n",
    "        # Initialize a counter for vertical_next_text\n",
    "        regression = 0\n",
    "        \n",
    "        # Iterate through the rows of the participant's data (except the last row)\n",
    "        for i in range(len(participant_data) - 1):\n",
    "            # Get the current and next row's aoi_y values\n",
    "            aoi_y_current = participant_data.iloc[i]['aoi_y']\n",
    "            aoi_y_next = participant_data.iloc[i + 1]['aoi_y']\n",
    "            aoi_x_current = participant_data.iloc[i]['aoi_x']\n",
    "            aoi_x_next = participant_data.iloc[i + 1]['aoi_x']\n",
    "            \n",
    "            # Check if the conditions are met\n",
    "            if ((aoi_y_current == aoi_y_next and aoi_x_current > aoi_x_next) or aoi_y_current > aoi_y_next):\n",
    "                regression += 1\n",
    "        \n",
    "        # Store the result for the current participant and the current file\n",
    "        all_results.append({'participant': participant, 'regression': regression, 'file': file})\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "results_df.to_csv('regression_experience.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a4b44700-2abd-4926-b237-82e6c0e46776",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ltr_aggregate.csv - Total regression: 5190\n",
      "File: rtl_aggregate.csv - Total regression: 239\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('vertical_next_experience.csv')\n",
    "\n",
    "# Group by the 'file' column and sum the 'vertical_next_text' column\n",
    "summed_df = df.groupby('file')['vertical_next'].sum().reset_index()\n",
    "\n",
    "# Print the summed values for each file\n",
    "for index, row in summed_df.iterrows():\n",
    "    print(f\"File: {row['file']} - Total regression: {row['vertical_next']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2c487ce4-c1db-48fe-8247-99d8bfdb55b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files combined successfully into 'combined_output.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the four CSV files\n",
    "df1 = pd.read_csv('duration_experience_programming_high_file.csv')\n",
    "df2 = pd.read_csv('duration_experience_programming_medium_file.csv')\n",
    "df3 = pd.read_csv('duration_experience_programming_low_file.csv')\n",
    "df4 = pd.read_csv('duration_experience_programming_none_file.csv')\n",
    "df5 = pd.read_csv('duration_experience_experiment_language_high_file.csv')\n",
    "df6 = pd.read_csv('duration_experience_experiment_language_medium_file.csv')\n",
    "df7 = pd.read_csv('duration_experience_experiment_language_low_file.csv')\n",
    "df8 = pd.read_csv('duration_experience_experiment_language_none_file.csv')\n",
    "\n",
    "# Rename the 'duration' column in each dataframe to indicate the source file\n",
    "df1 = df1.rename(columns={'duration': 'Programming High'})\n",
    "df2 = df2.rename(columns={'duration': 'Programming Medium'})\n",
    "df3 = df3.rename(columns={'duration': 'Programming Low'})\n",
    "df4 = df4.rename(columns={'duration': 'Programming None'})\n",
    "df5 = df5.rename(columns={'duration': 'Experiment Language High'})\n",
    "df6 = df6.rename(columns={'duration': 'Experiment Language Medium'})\n",
    "df7 = df7.rename(columns={'duration': 'Experiment Language Low'})\n",
    "df8 = df8.rename(columns={'duration': 'Experiment Language None'})\n",
    "\n",
    "# Divide the 'duration' column of the third file by 12\n",
    "df1['Programming High'] = df1['Programming High'] / 39\n",
    "df2['Programming Medium'] = df2['Programming Medium'] / 118\n",
    "df3['Programming Low'] = df3['Programming Low'] / 45\n",
    "df4['Programming None'] = df4['Programming None'] / 10\n",
    "df5['Experiment Language High'] = df5['Experiment Language High'] / 17\n",
    "df6['Experiment Language Medium'] = df6['Experiment Language Medium'] / 98\n",
    "df7['Experiment Language Low'] = df7['Experiment Language Low'] / 68\n",
    "df8['Experiment Language None'] = df8['Experiment Language None'] / 29\n",
    "\n",
    "# Merge the dataframes on the 'token' column\n",
    "merged_df = df1.merge(df2, on='token', how='outer')\\\n",
    "              .merge(df3, on='token', how='outer')\\\n",
    "              .merge(df4, on='token', how='outer') \\\n",
    "              .merge(df5, on='token', how='outer')\\\n",
    "              .merge(df6, on='token', how='outer') \\\n",
    "              .merge(df7, on='token', how='outer')\\\n",
    "              .merge(df8, on='token', how='outer') \n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "merged_df.to_csv('duration_experience_combined_output.csv', index=False)\n",
    "\n",
    "print(\"CSV files combined successfully into 'combined_output.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea473461-764f-402a-bfe1-25cc4b22abae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
